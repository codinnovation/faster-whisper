# Faster Whisper API Configuration

# Server Configuration
PORT=8000

# Whisper Model Configuration
# Model sizes: tiny, base, small, medium, large-v2, large-v3
# Larger models are more accurate but require more resources
WHISPER_MODEL_SIZE=base

# Device: cpu or cuda (for GPU acceleration)
WHISPER_DEVICE=cpu

# Compute type: int8, float16, float32
# int8 is fastest and uses least memory, float32 is most accurate
WHISPER_COMPUTE_TYPE=int8
